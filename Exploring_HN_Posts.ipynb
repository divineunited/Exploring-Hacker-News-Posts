{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "This data exploration will be analyzing posts from the site Hacker News from the year 2016. The dataset we will be analyzing can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). \n",
    "\n",
    "In this project, I will be using basic Python libraries and basic modules that don't require any extraneous installation - even though using a module like Pandas and/or MatPlotLib might make this analysis more efficient.\n",
    "\n",
    "The columns in the dataset can be described as follows:\n",
    "- `id` - The unique identifier from Hacker News for the post\n",
    "- `title` - The title of the post\n",
    "- `url` - The URL that the posts links to, if it the post has a URL\n",
    "- `num_points` - The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments` - The number of comments that were made on the post\n",
    "- `author` - The username of the person who submitted the post\n",
    "- `created_at` - The date and time at which the post was submitted\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. And users submit `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "Let's compare these two types of posts to determine the following:\n",
    "\n",
    "- **Do `Ask HN` or `Show HN` receive more comments on average?**\n",
    "- **Do posts created at a certain time receive more comments on average?**\n",
    "\n",
    "First, we'll import the dataset as a list of lists and display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "hn = list(csv.reader(open('HN_posts_year_to_Sep_26_2016.csv', encoding=\"utf-8\")))\n",
    "\n",
    "# saving the header seperately \n",
    "header = hn[0]\n",
    "\n",
    "# removing the header from the main dataset\n",
    "hn = hn[1:]\n",
    "\n",
    "print(header)\n",
    "print()\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to use regular expressions to filter out articles that begin with `Ask HN` or `Show HN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN articles: 9139 \n",
      " ['Ask HN: What TLD do you use for local development?', 'Ask HN: How do you pass on your work when you die?', 'Ask HN: How a DNS problem can be limited to a geographic region?', 'Ask HN: Why join a fund when you can be an angel?', 'Ask HN: Someone uses stock trading as passive income?'] \n",
      "\n",
      "Show HN articles: 10158 \n",
      " ['Show HN: Finding puns computationally', 'Show HN: A simple library for complicated animations', 'Show HN: WebGL visualization of DNA sequences', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'Show HN: Jumble  Essays on the go #PaulInYourPocket'] \n",
      "\n",
      "Other articles: 273822 \n",
      " ['You have two days to comment if you want stem cells to be classified as your own', 'SQLAR  the SQLite Archiver', 'What if we just printed a flatscreen television on the side of our boxes?', 'algorithmic music', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "# creating our re patterns that look for articles that start with the appropriate texts\n",
    "pattern_ask = r'^Ask HN'\n",
    "pattern_show = r'^Show HN'\n",
    "\n",
    "# filtering out articles into 3 different types using list comprehensions and regex\n",
    "ask_posts = [row for row in hn if re.search(pattern_ask, row[1], flags = re.I)]\n",
    "show_posts = [row for row in hn if re.search(pattern_show, row[1], flags = re.I)]\n",
    "other_posts = [row for row in hn if not (re.search(pattern_ask, row[1], flags = re.I) or re.search(pattern_show, row[1], flags = re.I))]\n",
    "\n",
    "# test printing some titles:\n",
    "print('Ask HN articles:', len(ask_posts), '\\n', [row[1] for row in ask_posts[0:5]], '\\n')\n",
    "print('Show HN articles:', len(show_posts), '\\n', [row[1] for row in show_posts[0:5]], '\\n')\n",
    "print('Other articles:', len(other_posts), '\\n', [row[1] for row in other_posts[0:5]], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's analyze these different datasets and see which types of articles recieve more comments: `Ask HN` vs `Show HN` articles. We will find the average number of comments for each using the `num_comments` column at index 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Hacker News - average number of comments:\n",
      "10.39\n",
      "\n",
      "Show Hacker News - average number of comments:\n",
      "4.89\n"
     ]
    }
   ],
   "source": [
    "# calculating average number of comments in each:\n",
    "avg_comments_ask = round(sum([int(row[4]) for row in ask_posts]) / len(ask_posts), 2)\n",
    "avg_comments_show = round(sum([int(row[4]) for row in show_posts]) / len(show_posts), 2)\n",
    "\n",
    "print('Ask Hacker News - average number of comments:')\n",
    "print(avg_comments_ask)\n",
    "print()\n",
    "print('Show Hacker News - average number of comments:')\n",
    "print(avg_comments_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no surprise and a good thing that the average number of comments for someone ASKING a question to Hacker News will be higher than someone posting something to SHOW the community something since people asking questions tend to get more answers and responses.\n",
    "\n",
    "**Since `Ask HN` posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.**\n",
    "\n",
    "# Time Based Analysis\n",
    "\n",
    "Next, we'll determine if Ask HN posts created at a certain time are more likely to attract comments. We are going to: \n",
    "- Calculate the number of Ask HN posts created in each hour of the day\n",
    "- Calculate the number of comments received based on hour of creation\n",
    "- Use the above information to calculate the average number of comments a single Ask HN post receives depending on the hour created.\n",
    "\n",
    "Let's calculate the number of `Ask HN` posts created in each hour of the day by creating a frequency table and using the `created_at` column at index 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out our results sorted by hour:\n",
      "(0, [301, 2277])\n",
      "(1, [282, 2089])\n",
      "(2, [269, 2996])\n",
      "(3, [271, 2154])\n",
      "(4, [243, 2360])\n",
      "(5, [209, 1838])\n",
      "(6, [234, 1587])\n",
      "(7, [226, 1585])\n",
      "(8, [257, 2362])\n",
      "(9, [222, 1477])\n",
      "(10, [282, 3013])\n",
      "(11, [312, 2797])\n",
      "(12, [342, 4234])\n",
      "(13, [444, 7245])\n",
      "(14, [513, 4972])\n",
      "(15, [646, 18525])\n",
      "(16, [579, 4466])\n",
      "(17, [587, 5547])\n",
      "(18, [614, 4877])\n",
      "(19, [552, 3954])\n",
      "(20, [510, 4462])\n",
      "(21, [518, 4500])\n",
      "(22, [383, 3372])\n",
      "(23, [343, 2297])\n",
      "\n",
      "Printing out our results sorted by most posts:\n",
      "(15, [646, 18525])\n",
      "(18, [614, 4877])\n",
      "(17, [587, 5547])\n",
      "(16, [579, 4466])\n",
      "(19, [552, 3954])\n",
      "(21, [518, 4500])\n",
      "(14, [513, 4972])\n",
      "(20, [510, 4462])\n",
      "(13, [444, 7245])\n",
      "(22, [383, 3372])\n",
      "(23, [343, 2297])\n",
      "(12, [342, 4234])\n",
      "(11, [312, 2797])\n",
      "(0, [301, 2277])\n",
      "(10, [282, 3013])\n",
      "(1, [282, 2089])\n",
      "(3, [271, 2154])\n",
      "(2, [269, 2996])\n",
      "(8, [257, 2362])\n",
      "(4, [243, 2360])\n",
      "(6, [234, 1587])\n",
      "(7, [226, 1585])\n",
      "(9, [222, 1477])\n",
      "(5, [209, 1838])\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# initializing our frequency table which will be a dictionary that stores hours as keys, \n",
    "# and a list of [posts created, num comments for posts created in that hour] as values\n",
    "posts_created_hour = {}\n",
    "\n",
    "# creating our frequency table for posts created at each hour of the day\n",
    "for row in ask_posts:\n",
    "    hour = dt.datetime.strptime(row[6], '%m/%d/%Y %H:%M').hour\n",
    "    numcomments = int(row[4])\n",
    "    if hour in posts_created_hour:\n",
    "        posts_created_hour.get(hour)[0] += 1\n",
    "        posts_created_hour.get(hour)[1] += numcomments\n",
    "    else:\n",
    "        posts_created_hour[hour] = [1, numcomments]\n",
    "\n",
    "print('Printing out our results sorted by hour:')\n",
    "print(*(item for item in sorted(posts_created_hour.items())), sep='\\n')\n",
    "\n",
    "print()\n",
    "print('Printing out our results sorted by most posts:')\n",
    "print(*(item for item in sorted(posts_created_hour.items(), key=lambda x: x[1], reverse=True)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, we have the most posts created between 3-4 pm followed by posts created between 6-7 pm.** Now, let's calculate the average number of comments based on the time the posts were created - which can be found by dividing the total number of comments by the total number of posts at a given hour.\n",
    "\n",
    "***We are attempting to infer that posts created at a given hour have more overall user activity.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out our results sorted by hour:\n",
      "[0, 7.5647840531561465]\n",
      "[1, 7.407801418439717]\n",
      "[2, 11.137546468401487]\n",
      "[3, 7.948339483394834]\n",
      "[4, 9.7119341563786]\n",
      "[5, 8.794258373205741]\n",
      "[6, 6.782051282051282]\n",
      "[7, 7.013274336283186]\n",
      "[8, 9.190661478599221]\n",
      "[9, 6.653153153153153]\n",
      "[10, 10.684397163120567]\n",
      "[11, 8.96474358974359]\n",
      "[12, 12.380116959064328]\n",
      "[13, 16.31756756756757]\n",
      "[14, 9.692007797270955]\n",
      "[15, 28.676470588235293]\n",
      "[16, 7.713298791018998]\n",
      "[17, 9.449744463373083]\n",
      "[18, 7.94299674267101]\n",
      "[19, 7.163043478260869]\n",
      "[20, 8.749019607843136]\n",
      "[21, 8.687258687258687]\n",
      "[22, 8.804177545691905]\n",
      "[23, 6.696793002915452]\n",
      "\n",
      "Results sorted by highest average number of comments based on time of date created:\n",
      "[15, 28.676470588235293]\n",
      "[13, 16.31756756756757]\n",
      "[12, 12.380116959064328]\n",
      "[2, 11.137546468401487]\n",
      "[10, 10.684397163120567]\n",
      "[4, 9.7119341563786]\n",
      "[14, 9.692007797270955]\n",
      "[17, 9.449744463373083]\n",
      "[8, 9.190661478599221]\n",
      "[11, 8.96474358974359]\n",
      "[22, 8.804177545691905]\n",
      "[5, 8.794258373205741]\n",
      "[20, 8.749019607843136]\n",
      "[21, 8.687258687258687]\n",
      "[3, 7.948339483394834]\n",
      "[18, 7.94299674267101]\n",
      "[16, 7.713298791018998]\n",
      "[0, 7.5647840531561465]\n",
      "[1, 7.407801418439717]\n",
      "[19, 7.163043478260869]\n",
      "[7, 7.013274336283186]\n",
      "[6, 6.782051282051282]\n",
      "[23, 6.696793002915452]\n",
      "[9, 6.653153153153153]\n"
     ]
    }
   ],
   "source": [
    "# using a list comprehension to create an average comments based on hour created:\n",
    "avg_comments_based_hour_created = [[key, posts_created_hour.get(key)[1] / posts_created_hour.get(key)[0]] for key in posts_created_hour]\n",
    "\n",
    "print('Printing out our results sorted by hour:')\n",
    "print(*(item for item in sorted(avg_comments_based_hour_created)), sep='\\n')\n",
    "\n",
    "print()\n",
    "print('Results sorted by highest average number of comments based on time of date created:')\n",
    "print(*(item for item in sorted(avg_comments_based_hour_created, key = lambda x: x[1], reverse=True)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, posts created between 3-4 pm have nearly double the amount of comments / activity compared to other posts. Whereas posts created between 9-10 am have the least amount of activity.** This can possibly be explained since people are usually beginning their work day from 9-10 am and starting to finish their work day around 3-4 pm.\n",
    "\n",
    "We can first check to see if there are any posts created during this hour that have numbers that might skew our analysis and remove these standard deviations.\n",
    "\n",
    "# Conclusion\n",
    "Using the evidence from our analysis, creating a post - or at least asking a question to Hacker News - between 3-4 pm will generate the most user activity / comments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
