{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Hacker News Posts\n",
    "\n",
    "This data exploration will be analyzing posts from the site Hacker News from the year 2016. The dataset we will be analyzing can be found [here](https://www.kaggle.com/hacker-news/hacker-news-posts). \n",
    "\n",
    "In this project, I will be using basic Python libraries and basic modules that don't require any extraneous installation - even though using a module like Pandas and/or MatPlotLib might make this analysis more efficient.\n",
    "\n",
    "The columns in the dataset can be described as follows:\n",
    "- `id` - The unique identifier from Hacker News for the post\n",
    "- `title` - The title of the post\n",
    "- `url` - The URL that the posts links to, if it the post has a URL\n",
    "- `num_points` - The number of points the post acquired, calculated as the total number of upvotes minus the total number of downvotes\n",
    "- `num_comments` - The number of comments that were made on the post\n",
    "- `author` - The username of the person who submitted the post\n",
    "- `created_at` - The date and time at which the post was submitted\n",
    "\n",
    "We're specifically interested in posts whose titles begin with either `Ask HN` or `Show HN`. Users submit `Ask HN` posts to ask the Hacker News community a specific question. And users submit `Show HN` posts to show the Hacker News community a project, product, or just generally something interesting.\n",
    "\n",
    "Let's compare these two types of posts to determine the following:\n",
    "\n",
    "- **Do `Ask HN` or `Show HN` receive more comments on average?**\n",
    "- **Do posts created at a certain time receive more comments on average?**\n",
    "\n",
    "First, we'll import the dataset as a list of lists and display the first five rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "[['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'], ['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'], ['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'], ['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'], ['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "hn = list(csv.reader(open('HN_posts_year_to_Sep_26_2016.csv', encoding=\"utf-8\")))\n",
    "\n",
    "# saving the header seperately \n",
    "header = hn[0]\n",
    "\n",
    "# removing the header from the main dataset\n",
    "hn = hn[1:]\n",
    "\n",
    "print(header)\n",
    "print()\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we're going to use regular expressions to filter out articles that begin with `Ask HN` or `Show HN`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask HN articles: 9139 \n",
      " ['Ask HN: What TLD do you use for local development?', 'Ask HN: How do you pass on your work when you die?', 'Ask HN: How a DNS problem can be limited to a geographic region?', 'Ask HN: Why join a fund when you can be an angel?', 'Ask HN: Someone uses stock trading as passive income?'] \n",
      "\n",
      "Show HN articles: 10158 \n",
      " ['Show HN: Finding puns computationally', 'Show HN: A simple library for complicated animations', 'Show HN: WebGL visualization of DNA sequences', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'Show HN: Jumble  Essays on the go #PaulInYourPocket'] \n",
      "\n",
      "Other articles: 273822 \n",
      " ['You have two days to comment if you want stem cells to be classified as your own', 'SQLAR  the SQLite Archiver', 'What if we just printed a flatscreen television on the side of our boxes?', 'algorithmic music', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "# creating our re patterns that look for articles that start with the appropriate texts\n",
    "pattern_ask = r'^Ask HN'\n",
    "pattern_show = r'^Show HN'\n",
    "\n",
    "# filtering out articles into 3 different types using list comprehensions and regex\n",
    "ask_posts = [row for row in hn if re.search(pattern_ask, row[1], flags = re.I)]\n",
    "show_posts = [row for row in hn if re.search(pattern_show, row[1], flags = re.I)]\n",
    "other_posts = [row for row in hn if not (re.search(pattern_ask, row[1], flags = re.I) or re.search(pattern_show, row[1], flags = re.I))]\n",
    "\n",
    "# test printing some titles:\n",
    "print('Ask HN articles:', len(ask_posts), '\\n', [row[1] for row in ask_posts[0:5]], '\\n')\n",
    "print('Show HN articles:', len(show_posts), '\\n', [row[1] for row in show_posts[0:5]], '\\n')\n",
    "print('Other articles:', len(other_posts), '\\n', [row[1] for row in other_posts[0:5]], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's analyze these different datasets and see which types of articles recieve more comments: `Ask HN` vs `Show HN` articles. We will find the average number of comments for each using the `num_comments` column at index 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ask Hacker News - average number of comments:\n",
      "10.39\n",
      "\n",
      "Show Hacker News - average number of comments:\n",
      "4.89\n"
     ]
    }
   ],
   "source": [
    "# calculating average number of comments in each:\n",
    "avg_comments_ask = round(sum([int(row[4]) for row in ask_posts]) / len(ask_posts), 2)\n",
    "avg_comments_show = round(sum([int(row[4]) for row in show_posts]) / len(show_posts), 2)\n",
    "\n",
    "print('Ask Hacker News - average number of comments:')\n",
    "print(avg_comments_ask)\n",
    "print()\n",
    "print('Show Hacker News - average number of comments:')\n",
    "print(avg_comments_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's no surprise and a good thing that the average number of comments for someone ASKING a question to Hacker News will be higher than someone posting something to SHOW the community something since people asking questions tend to get more answers and responses.\n",
    "\n",
    "**Since `Ask HN` posts are more likely to receive comments, we'll focus our remaining analysis just on these posts.**\n",
    "\n",
    "# Time Based Analysis\n",
    "\n",
    "Next, we'll determine if Ask HN posts created at a certain time are more likely to attract comments. We are going to: \n",
    "- Calculate the number of Ask HN posts created in each hour of the day\n",
    "- Calculate the number of comments received based on hour of creation\n",
    "- Use the above information to calculate the average number of comments a single Ask HN post receives depending on the hour created.\n",
    "\n",
    "Let's calculate the number of `Ask HN` posts created in each hour of the day by creating a frequency table and using the `created_at` column at index 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out our results sorted by hour:\n",
      "Time       #_Posts  #_Comments\n",
      "12:00 AM   301      2277      \n",
      "01:00 AM   282      2089      \n",
      "02:00 AM   269      2996      \n",
      "03:00 AM   271      2154      \n",
      "04:00 AM   243      2360      \n",
      "05:00 AM   209      1838      \n",
      "06:00 AM   234      1587      \n",
      "07:00 AM   226      1585      \n",
      "08:00 AM   257      2362      \n",
      "09:00 AM   222      1477      \n",
      "10:00 AM   282      3013      \n",
      "11:00 AM   312      2797      \n",
      "12:00 PM   342      4234      \n",
      "01:00 PM   444      7245      \n",
      "02:00 PM   513      4972      \n",
      "03:00 PM   646      18525     \n",
      "04:00 PM   579      4466      \n",
      "05:00 PM   587      5547      \n",
      "06:00 PM   614      4877      \n",
      "07:00 PM   552      3954      \n",
      "08:00 PM   510      4462      \n",
      "09:00 PM   518      4500      \n",
      "10:00 PM   383      3372      \n",
      "11:00 PM   343      2297      \n",
      "\n",
      "Printing out our results sorted by most posts:\n",
      "Time       #_Posts  #_Comments\n",
      "03:00 PM   646      18525     \n",
      "06:00 PM   614      4877      \n",
      "05:00 PM   587      5547      \n",
      "04:00 PM   579      4466      \n",
      "07:00 PM   552      3954      \n",
      "09:00 PM   518      4500      \n",
      "02:00 PM   513      4972      \n",
      "08:00 PM   510      4462      \n",
      "01:00 PM   444      7245      \n",
      "10:00 PM   383      3372      \n",
      "11:00 PM   343      2297      \n",
      "12:00 PM   342      4234      \n",
      "11:00 AM   312      2797      \n",
      "12:00 AM   301      2277      \n",
      "10:00 AM   282      3013      \n",
      "01:00 AM   282      2089      \n",
      "03:00 AM   271      2154      \n",
      "02:00 AM   269      2996      \n",
      "08:00 AM   257      2362      \n",
      "04:00 AM   243      2360      \n",
      "06:00 AM   234      1587      \n",
      "07:00 AM   226      1585      \n",
      "09:00 AM   222      1477      \n",
      "05:00 AM   209      1838      \n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "\n",
    "# initializing our frequency table which will be a dictionary that stores hours as keys, \n",
    "# and a list of [posts created, num comments for posts created in that hour] as values\n",
    "posts_created_hour = {}\n",
    "\n",
    "# creating our frequency table for posts created at each hour of the day\n",
    "for row in ask_posts:\n",
    "    hour = dt.datetime.strptime(row[6], '%m/%d/%Y %H:%M').hour\n",
    "    numcomments = int(row[4])\n",
    "    if hour in posts_created_hour:\n",
    "        posts_created_hour.get(hour)[0] += 1\n",
    "        posts_created_hour.get(hour)[1] += numcomments\n",
    "    else:\n",
    "        posts_created_hour[hour] = [1, numcomments]\n",
    "\n",
    "# sorting by hour:\n",
    "posts_sorted_hour = sorted(posts_created_hour.items())\n",
    "posts_sorted_posts = sorted(posts_created_hour.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# creating an output print format for the table:\n",
    "output = \"{0:<10} {1:<8} {2:<10}\"\n",
    "\n",
    "print('Printing out our results sorted by hour:')\n",
    "print(output.format(\"Time\", \"#_Posts\", \"#_Comments\"))\n",
    "for row in posts_sorted_hour:\n",
    "    time = dt.datetime(2016, 1, 1, hour=row[0])\n",
    "    numposts = row[1][0]\n",
    "    numcomments = row[1][1]\n",
    "    print(output.format(time.strftime('%I:%M %p'), numposts, numcomments))\n",
    "\n",
    "print()\n",
    "print('Printing out our results sorted by most posts:')\n",
    "print(output.format(\"Time\", \"#_Posts\", \"#_Comments\"))\n",
    "for row in posts_sorted_posts:\n",
    "    time = dt.datetime(2016, 1, 1, hour=row[0])\n",
    "    numposts = row[1][0]\n",
    "    numcomments = row[1][1]\n",
    "    print(output.format(time.strftime('%I:%M %p'), numposts, numcomments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As you can see, we have the most posts created between 3-4 pm followed by posts created between 6-7 pm.** Now, let's calculate the average number of comments based on the time the posts were created - which can be found by dividing the total number of comments by the total number of posts at a given hour.\n",
    "\n",
    "***We are attempting to infer that posts created at a given hour have more overall user activity.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out our results sorted by hour:\n",
      "[0, 7.5647840531561465]\n",
      "[1, 7.407801418439717]\n",
      "[2, 11.137546468401487]\n",
      "[3, 7.948339483394834]\n",
      "[4, 9.7119341563786]\n",
      "[5, 8.794258373205741]\n",
      "[6, 6.782051282051282]\n",
      "[7, 7.013274336283186]\n",
      "[8, 9.190661478599221]\n",
      "[9, 6.653153153153153]\n",
      "[10, 10.684397163120567]\n",
      "[11, 8.96474358974359]\n",
      "[12, 12.380116959064328]\n",
      "[13, 16.31756756756757]\n",
      "[14, 9.692007797270955]\n",
      "[15, 28.676470588235293]\n",
      "[16, 7.713298791018998]\n",
      "[17, 9.449744463373083]\n",
      "[18, 7.94299674267101]\n",
      "[19, 7.163043478260869]\n",
      "[20, 8.749019607843136]\n",
      "[21, 8.687258687258687]\n",
      "[22, 8.804177545691905]\n",
      "[23, 6.696793002915452]\n",
      "\n",
      "Results sorted by highest average number of comments based on time of date created:\n",
      "[15, 28.676470588235293]\n",
      "[13, 16.31756756756757]\n",
      "[12, 12.380116959064328]\n",
      "[2, 11.137546468401487]\n",
      "[10, 10.684397163120567]\n",
      "[4, 9.7119341563786]\n",
      "[14, 9.692007797270955]\n",
      "[17, 9.449744463373083]\n",
      "[8, 9.190661478599221]\n",
      "[11, 8.96474358974359]\n",
      "[22, 8.804177545691905]\n",
      "[5, 8.794258373205741]\n",
      "[20, 8.749019607843136]\n",
      "[21, 8.687258687258687]\n",
      "[3, 7.948339483394834]\n",
      "[18, 7.94299674267101]\n",
      "[16, 7.713298791018998]\n",
      "[0, 7.5647840531561465]\n",
      "[1, 7.407801418439717]\n",
      "[19, 7.163043478260869]\n",
      "[7, 7.013274336283186]\n",
      "[6, 6.782051282051282]\n",
      "[23, 6.696793002915452]\n",
      "[9, 6.653153153153153]\n"
     ]
    }
   ],
   "source": [
    "# using a list comprehension to create an average comments based on hour created:\n",
    "avg_comments_based_hour_created = [[key, posts_created_hour.get(key)[1] / posts_created_hour.get(key)[0]] for key in posts_created_hour]\n",
    "\n",
    "print('Printing out our results sorted by hour:')\n",
    "print(*(item for item in sorted(avg_comments_based_hour_created)), sep='\\n')\n",
    "\n",
    "print()\n",
    "print('Results sorted by highest average number of comments based on time of date created:')\n",
    "print(*(item for item in sorted(avg_comments_based_hour_created, key = lambda x: x[1], reverse=True)), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As we can see, posts created between 3-4 pm have nearly double the amount of comments / activity compared to other posts. Whereas posts created between 9-10 am have the least amount of activity.** This can possibly be explained since people are usually beginning their work day from 9-10 am and starting to finish their work day around 3-4 pm so they would have more time to write comments and read posts on Hacker News.\n",
    "\n",
    "Before we come to our conclusion, let's check to see if there are any posts created during this hour that are extreme outliers with really large numbers that might skew our analysis and see if we need to remove any of these standard deviations.\n",
    "\n",
    "# FINDING OUTLIERS\n",
    "\n",
    "Let's see what makes these posts at 3 pm unique and analyze further the articles posted from 3-4 pm by printing out the posts with the highest number of comments at that time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1007 : Ask HN: Who is hiring? (June 2016)\n",
      "947 : Ask HN: Who is hiring? (August 2016)\n",
      "937 : Ask HN: Who is hiring? (May 2016)\n",
      "910 : Ask HN: Who is hiring? (September 2016)\n",
      "898 : Ask HN: Who is hiring? (July 2016)\n",
      "896 : Ask HN: Who is hiring? (November 2015)\n",
      "825 : Ask HN: Who is hiring? (March 2016)\n",
      "778 : Ask HN: Who is hiring? (February 2016)\n",
      "720 : Ask HN: Who is hiring? (April 2016)\n",
      "705 : Ask HN: Who is hiring? (October 2015)\n",
      "626 : Ask HN: What are you working on and why is it awesome? Please include URL\n",
      "472 : Ask HN: Who is hiring? (January 2016)\n",
      "431 : Ask HN: Who is hiring? (December 2015)\n",
      "283 : Ask HN: Who wants to be hired? (April 2016)\n",
      "258 : Ask HN: What are some examples of beautiful software?\n",
      "250 : Ask HN: Who wants to be hired? (June 2016)\n",
      "210 : Ask HN: Who wants to be hired? (July 2016)\n",
      "202 : Ask HN: Who wants to be hired? (March 2016)\n",
      "200 : Ask HN: Freelancer? Seeking freelancer? (June 2016)\n",
      "169 : Ask HN: Who wants to be hired? (May 2016)\n",
      "166 : Ask HN: Who wants to be hired? (September 2016)\n",
      "162 : Ask HN: What sites do you use to find contract work?\n",
      "158 : Ask HN: Freelancer? Seeking freelancer? (November 2015)\n",
      "156 : Ask HN: How did you learn about stocks and the market?\n",
      "148 : Ask HN: Freelancer? Seeking freelancer? (January 2016)\n",
      "144 : Ask HN: Do I have to go through recruiters nowadays, how do you find new jobs?\n",
      "142 : Ask HN: What's your primary development laptop?\n",
      "138 : Ask HN: Freelancer? Seeking freelancer? (May 2016)\n",
      "135 : Ask HN: How do you get notified about newest research papers in your field?\n",
      "129 : Ask HN: Freelancer? Seeking freelancer? (April 2016)\n",
      "128 : Ask HN: What to do when a Chinese startup clones your website?\n",
      "127 : Ask HN: Freelancer? Seeking freelancer? (August 2016)\n",
      "127 : Ask HN: Who wants to be hired? (February 2016)\n",
      "118 : Ask HN: Who wants to be hired? (August 2016)\n",
      "118 : Ask HN: What was your best passive income in 2015?\n",
      "117 : Ask HN: Cheap dedicated hosting options for side projects\n",
      "111 : Ask HN: GitHub vs. Gitlab?\n",
      "110 : Ask HN: Who wants to be hired? (January 2016)\n",
      "107 : Ask HN: Freelancer? Seeking freelancer? (October 2015)\n",
      "104 : Ask HN: How much job hopping is acceptable?\n",
      "101 : Ask HN: Who wants to be hired? (November 2015)\n",
      "101 : Ask HN: Who wants to be hired? (October 2015)\n",
      "97 : Ask HN: How do I fire someone who has sensitive data on their personal laptop?\n",
      "95 : Ask HN: What are good reads for designing APIs?\n",
      "95 : Ask HN: Who wants to be hired? (December 2015)\n",
      "93 : Ask HN: Freelancer? Seeking freelancer? (December 2015)\n",
      "89 : Ask HN: How have you left Google's services?\n",
      "85 : Ask HN: Freelancer? Seeking freelancer? (September 2016)\n",
      "84 : Ask HN: Freelancer? Seeking freelancer? (March 2016)\n",
      "84 : Ask HN: Freelancer? Seeking freelancer? (February 2016)\n"
     ]
    }
   ],
   "source": [
    "# filtering out all posts that are posted at 3 pm\n",
    "three_pm_posts = [row for row in ask_posts if dt.datetime.strptime(row[6], '%m/%d/%Y %H:%M').hour == 15]\n",
    "\n",
    "# sorting the posts by maximum number of comments\n",
    "three_pm_posts = sorted(three_pm_posts, key = lambda x: int(x[4]), reverse = True)\n",
    "\n",
    "# printing the top 50 posts with the highest number of comments\n",
    "for row in three_pm_posts[0:50]:\n",
    "    print(row[4], ':', row[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of comments seems to gradually fall and it looks like there aren't any extreme single outliers that we need to remove. However, the top posts of this hour are ones that ask the question `Who is hiring?`. If people only post these `Who is hiring?` questions at a certain time from 3-4 pm each day, that could be a reason why there is such an uptick of activity in this time period. Let's do a frequency table of `Who is hiring?` posts throughout the day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing out our results of WHO IS HIRING posts sorted by hour:\n",
      "Time       #_Posts  #_Comments\n",
      "02:00 AM   2        120       \n",
      "09:00 AM   1        2         \n",
      "01:00 PM   2        16        \n",
      "03:00 PM   13       9526      \n",
      "05:00 PM   1        0         \n",
      "06:00 PM   1        2         \n",
      "07:00 PM   2        1         \n",
      "08:00 PM   1        0         \n",
      "09:00 PM   1        2         \n",
      "\n",
      "Printing out our results of WHO IS HIRING posts sorted by most posts:\n",
      "Time       #_Posts  #_Comments\n",
      "03:00 PM   13       9526      \n",
      "02:00 AM   2        120       \n",
      "01:00 PM   2        16        \n",
      "07:00 PM   2        1         \n",
      "06:00 PM   1        2         \n",
      "09:00 AM   1        2         \n",
      "09:00 PM   1        2         \n",
      "08:00 PM   1        0         \n",
      "05:00 PM   1        0         \n"
     ]
    }
   ],
   "source": [
    "hiring_posts = [row for row in ask_posts if re.search(r'Who is hiring?', row[1], flags = re.I)]\n",
    "hiring_posts_created_hour = {}\n",
    "\n",
    "# creating our frequency table for 'who is hiring' posts created at each hour of the day\n",
    "for row in hiring_posts:\n",
    "    hour = dt.datetime.strptime(row[6], '%m/%d/%Y %H:%M').hour\n",
    "    numcomments = int(row[4])\n",
    "    if hour in hiring_posts_created_hour:\n",
    "        hiring_posts_created_hour.get(hour)[0] += 1\n",
    "        hiring_posts_created_hour.get(hour)[1] += numcomments\n",
    "    else:\n",
    "        hiring_posts_created_hour[hour] = [1, numcomments]\n",
    "\n",
    "# sorting by hour:\n",
    "hiring_posts_sorted_hour = sorted(hiring_posts_created_hour.items())\n",
    "hiring_posts_sorted_posts = sorted(hiring_posts_created_hour.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# creating an output print format for the table:\n",
    "output = \"{0:<10} {1:<8} {2:<10}\"\n",
    "\n",
    "print('Printing out our results of WHO IS HIRING posts sorted by hour:')\n",
    "print(output.format(\"Time\", \"#_Posts\", \"#_Comments\"))\n",
    "for row in hiring_posts_sorted_hour:\n",
    "    time = dt.datetime(2016, 1, 1, hour=row[0])\n",
    "    numposts = row[1][0]\n",
    "    numcomments = row[1][1]\n",
    "    print(output.format(time.strftime('%I:%M %p'), numposts, numcomments))\n",
    "\n",
    "print()\n",
    "print('Printing out our results of WHO IS HIRING posts sorted by most posts:')\n",
    "print(output.format(\"Time\", \"#_Posts\", \"#_Comments\"))\n",
    "for row in hiring_posts_sorted_posts:\n",
    "    time = dt.datetime(2016, 1, 1, hour=row[0])\n",
    "    numposts = row[1][0]\n",
    "    numcomments = row[1][1]\n",
    "    print(output.format(time.strftime('%I:%M %p'), numposts, numcomments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! - it seems that our outliers that cause this uptick at the 3-4 pm time interval (or our standard deviation) is the `Who is hiring` articles. Even though there are other times when these articles are posted, the 13 articles posted at 3-4 pm have 9,526 comments combined!\n",
    "\n",
    "# Removing the Discovered Outliers\n",
    "\n",
    "Let's remove the outliers in our data by re-running the code above and purposely filtering out \"Who is hiring\" posts using regular expressions and then check again to see what our averages look like by hour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
